##############################################################################
#
#   Snakemake pipeline:
#   {{cookiecutter.project_name}}
#
#   AUTHOR: {{cookiecutter.author}}
#   AFFILIATION: {{cookiecutter.affiliation}}
#   CONTACT: {{cookiecutter.contact}}
#   CREATED: {{cookiecutter.date_created}}
#   LICENSE: {{cookiecutter.license}}
#
##############################################################################

# imports
import sys
import os

# local rules
localrules: all

# create output subdirectories
os.makedirs(config['output_dir'], exist_ok=True)
os.makedirs(
    os.path.join(
        config['output_dir'],
        "results"
    ),
    exist_ok=True)
os.makedirs(
    os.path.join(
        config['output_dir'],
        "local_log"
    ),
    exist_ok=True)
if cluster_config:
    os.makedirs(
        os.path.join(
            config['output_dir'],
            "cluster_log"
        ),
        exist_ok=True)

##############################################################################
### Target rule with final output of the pipeline
##############################################################################

rule all:
    '''
    Gathering all output
    '''
    input:
        TXT_final_results = expand(
            os.path.join(
                "{output_dir}",
                "results",
                "results.txt"
            ),
            output_dir=config["output_dir"])

##############################################################################
### Sample some random data
##############################################################################

rule generate_files:
    '''
    Sampling random numbers
    '''
    input:
        SCRIPT = os.path.join(
            config["src_dir"],
            "mb_random_sample.py")

    output:
        TXT_random_sample = os.path.join(
            "{output_dir}",
            "results",
            "random_samples",
            "{file}")

    params:
        LOG_cluster_log = os.path.join(
            "{output_dir}",
            "cluster_log",
            "generate_files_{file}.log"),
        queue = "30min",
        time = "0:05:00"

    log:
        LOG_local_stdout = os.path.join(
            "{output_dir}",
            "local_log",
            "generate_files_{file}.stdout.log"),
        LOG_local_stderr = os.path.join(
            "{output_dir}",
            "local_log",
            "generate_files_{file}.stderr.log")

    resources:
        threads = 1,
        mem = 5000

    benchmark:
        os.path.join(
            "{output_dir}",
            "local_log",
            "generate_files_{file}.benchmark.log")

    conda:
        "packages.yml"

    container:
        ""

    shell:
        """
        python {input.SCRIPT} \
        --outfile {output.TXT_random_sample} \
        1> {log.LOG_local_stdout} 2> {log.LOG_local_stderr}
        """

##############################################################################
### Merge the results
##############################################################################

rule merge_results:
    '''
    Concatenating all files into one
    '''
    input:
        TXT_result_files = \
            lambda wildcards: \
                [os.path.join(
                    wildcards.output_dir,
                    "results",
                    "random_samples",
                    f)
                for f in config["samples_filenames"]]

    output:
        TXT_final_results = os.path.join(
            "{output_dir}",
            "results",
            "results.txt")

    params:
        LOG_cluster_log = os.path.join(
            "{output_dir}",
            "cluster_log",
            "merge_results.log"),
        queue = "30min",
        time = "00:05:00"

    resources:
        threads = 1,
        mem = 5000

    log:
        LOG_local_stdout = os.path.join(
            "{output_dir}",
            "local_log",
            "merge_results.stdout.log"),
        LOG_local_stderr = os.path.join(
            "{output_dir}",
            "local_log",
            "merge_results.stderr.log")

    run:
        # read all the sampled numbers:
        numbers = []
        for i in input.TXT_result_files:
            with open(i) as f:
                numbers.append(f.read().splitlines()[0])
        # save into one file:
        with open(output.TXT_final_results, "w") as outfile:
                outfile.write("\n".join(numbers))

